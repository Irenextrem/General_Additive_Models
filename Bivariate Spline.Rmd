---
title: "P6 MAS Suavizado Bivariante"
author: "Irene Extremera Serrano"
date: "30/5/2020"
output: word_document
---

<!-- ```{r global_options, include=FALSE, message=FALSE,fig.align="center"} -->
<!--  knitr::opts_chunk$set(warning=FALSE) -->
<!-- ``` -->

 <!-- fig.width=10,fig.height=3 -->
 
<!-- warning=FALSE, error=FALSE -->

```{r}
library(nlme) 
library(mgcv) 
library(readxl) 
library(readr)
library(glmulti) 
library(boot) 
library(rJava)
library(HRW)
library(gamair)

setwd('D:/Desktop/Remember/Estudios/Educación Formal/Máster/Máster Valencia/Bioestadística/Curso 1/20 3-6Modelización Avanzada/Modelos Aditivos y Suavizado/Tareas/Tarea 6')
VaricellaData2013 <- read_delim("D:/Desktop/Remember/Estudios/Educación Formal/Máster/Máster Valencia/Bioestadística/Curso 1/20 3-6Modelización Avanzada/Modelos Aditivos y Suavizado/Tareas/Tarea 6/VaricellaData2013.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
```

```{r}
#Me quedo con las variables que voy a usar
varicela <- VaricellaData2013[,c(4,5,6,7,8)]
```


En el la base de datos con la que se va a trabajar de nombre VaricellaData2013.csv se presentan los casos de varicela en la ciudad de Valencia, del año 2013. La información está desglosada por barrios. También se recoge el total de población de cada barrio y la población menor de 5 años en forma de porcentaje.
se recoge. Además, se incluyen las variables de geolocalización x e y de cada uno de los barrios.

#Apartado 1

En este primer ajuste se realizará un modelo que trate de explicar la variable casos notificados ~$Poisson(\lambda)$ a partir de las variables explicativas población total y porcentaje de población mayor de 5 años haciendo uso de un modelo lineal generalizado. Además se valorará la posibilidad de incluir o no la interacción de ambas variables en el modelo final.

Antes de proceder al análisis se realizará una pequeña descriptiva para ver si esta puede arrojar luz en los ajustes que se hagan posteriormente

```{r}
attach(varicela)

#Variables individualmente
par(mfrow=c(1,3))
boxplot(Counts13,main='Número de casos')
boxplot(Total_Pob13,main='Población Total')
boxplot(por_menor5,main='% <5 años')

#Comparación dos a dos
par(mfrow=c(1,1))
pairs(varicela)
cor(varicela)
```

En los diagramas de cajas se puede apreciar que hay un valor atípico en los tres que despunta bastante el cual podría afectar en el ajuste del modelo.

Con respecto a los gráficos dos a dos se puede apreciar que hay un ligera relación lineal entre el número de casos y la población total ya que parece que se podría ajustar con una linea recta. El resto de relaciones parece no estar tan clara.

Lo mencionado anteriormente se confirma observando la correlación entre variables, en donde el número de casos y la población total presentan un valor de 0.756. El resto de relaciones son bastante débiles no llegando a superar la correlación de +/-0.20.

Tras esta pequeña descriptiva se procede a realizar el ajuste mediante un glm en donde las variables explicativas a usar serán el % de menores de 5 años y la población total.

Como lo que se va a modelizar es la media mediante $log(\lambda)$ de la distribución Poisson frente al predictor lineal.

```{r}
m1 <- glm(Counts13~Total_Pob13*por_menor5, family = poisson)
summary(m1)
par(mfrow=c(2,2))
plot(m1)
```

En el modelo salen todos los coeficientes significativos a excepción del intercepto. 
Aparte, cuando se miran los residuos se aprecia que la mayor parte quedan a la izquierda y el gráfico QQ tiene la cola de la derecha con un comportamiento alejado de la normalidad.
Mencionar que en el gráfico de Leverage se aprecia que hay un valor correspondiente al individuo 67 que va a influir en el ajuste del mdoelo ya que sobrepasa la distancia de Cook.

Visto los residuos anteriores, se lleva a que se considere que tal vez con la función step se consiga un modelo mejor.

```{r}
step(m1)
```

El modelo propuesto por step es el mismo que el generado al principio, pues incluye la interacción de ambas variables.
Sin embargo, se plantea que tal vez pueda prescindirse de la interacción, por lo tanto se realizará un modelo en el cual no la incluya, también se hará una comparativa de ambos modelos en términos de diferencia de deviance, deviance explicada, AIC y capacidad predictiva.

```{r}
m2 <- glm(Counts13~Total_Pob13+por_menor5, family = poisson)

#Comparación mediante chi cuadrado
pchisq(abs(m1$deviance-m2$deviance), abs(m1$df.residual-m2$df.residual),lower.tail = FALSE)
```

Según el análisis $X^2$ hay diferencias significativas entre ambos modelos,p valor menor a 0.05, por lo tanto a continuación se compararán ambos modelos a ver cuál de los dos será el idóneo a usar.

```{r}
#AIC
m1$aic
m2$aic
```

```{r}
#Deviance explicada
round(100-(m1$deviance/m1$null.deviance)*100,2)
round(100-(m2$deviance/m2$null.deviance)*100,2)
```

```{r}
#Capacidad predictiva
cv_int <- cv.glm(varicela, m1)
cv_sum <- cv.glm(varicela, m2)

cv_int$delta[2]
cv_sum$delta[2]
```

El error de predicción del modelo sin interacción es menor, de 55.39, en comparación al error del modelo con interación, de 61.14.

Por lo que en estas circunstancias se concluye que en función de cuál sea el objetivo del estudio, si generar un modelo que se ajuste bien a los datos o que consiga unas buenas predicciones se eligirá un modelo u otro.

Por un lado, a la vista de que los valores de AIC y deviance explicada no difieren mucho y tras un contraste $X^2$ en el que hay una diferencia entre ambos modelos, lo idóneo sería decantarse por el modelo más sencillo, el cual no incluye la interación pues predice mejor.

Por otro lado, el objetivo del apartado es buscar el modelo que mejora la explicación de los casos notificados, por lo que el modelo seleccionado será el que mejor se ajusta a los datos y no el que mejor predice. Es decir, el modelo que incluye la interación.

Por lo que el modelo definitivo en este apartado tendría la siguiente forma:

$log(\lambda)=\beta_0+\beta_1t_i+\beta_2c_i+\beta_3t_ic_i$
$\lambda=exp(\beta_0+\beta_1t_i+\beta_2c_i+\beta_3t_ic_i)$


La media del número de casos de varicela sería el resultado de la exponencial de la suma de un valor fijo al producto de un coeficiente y la población total, más el producto de un coeficiente y el porcentaje de población inferior a 5 años y el producto de la interacción de ambas con un coeficiente. 

Para finalizar el apartado, se valorará la bondad de ajuste de ambos modelos, para ello se usarán los residuos deviance y se les pasará el shapiro test para valorar la normalidad y el test de levene para valorar la heterocedasticidad.

```{r}
#Bondad de ajuste
#Con interacción
shapiro.test(residuals(m1, type='deviance'))

grupos <- cut(m1$fitted.values, quantile(m1$fitted.values, (0:4)/4))
lawstat::levene.test(residuals(m1, type='deviance'), grupos)

#Sin interacción
shapiro.test(residuals(m2, type='deviance'))

grupos <- cut(m2$fitted.values, quantile(m2$fitted.values, (0:4)/4))
lawstat::levene.test(residuals(m2, type='deviance'), grupos)
```

Ambos modelos cumplen la hipótesis de heterocedasticidad (0.56 y 0.70) pero no la de normalidad (0.0004 y 0.0006), por lo tanto probablemente sea indicativo de que el valor atípico visto anteriormente en la descriptiva (individuo 67) esté afectando al ajuste del modelo y por ello no pase las condiciones.

De modo que como propuesta de futuro lo idóneo sería considerar que es un caso de sobredispersión y realizar el modelo pero usando una distribución alternativa como puede ser una distribución binomial negativa. Otra cosa a considerar es realizar el ajuste sin tener en cuenta el valor atípico observado al comienzo de la descriptiva porque tal vez sea el que está dando problemas en el ajuste.

# Apartado 2

En el siguiente apartado se realizará un gam para explicar los casos notificados a partir de la suavización bivariante de la población total y el porcentaje de población menor a 5 años.

Al ser un GAM bivariante se realizarán dos modelos con distintas bases para valorar si hay diferencias marcadas entre ambos y decantarse con el modelo cuya base permita un mejor ajuste. Una de las bases con las que se trabajará será **thin plate**, la cual genera el mismo grado de suavización en todas las direcciones y es invariante por rotación. Aparte, la otra base con la que se trabajará será **tensor product** la cual, a diferencia de la anterior, no tiene el mismo grado de suavizado en ambas covariables y además no es invariante por rotación. 
Con respecto al número de nodos, se pondrán 7 y se ha decidido así debido a que cuando el valor de n es menor de 30 lo idóneo es poner 3, en este caso que se disponen de 70 datos se ha considerado oportuno. Sin embargo, debido a que la definición de las bases es diferente, para igualar en grados de libertad, a al modelo ajustado por thin plate se le han dado 53 nodos. De ese modo la comparación entre ambos modelos es mucho más justa.

```{r}
gam1a<- gam(Counts13~s(Total_Pob13,por_menor5, bs='tp',k=53),family = poisson)
gam1b<- gam(Counts13~te(Total_Pob13,por_menor5,k=7),family = poisson)

summary(gam1a)
summary(gam1b)
```

En ambos modelos, tanto el intercepto como el suavizado bivariante salen significativas. Además el valor de edf en ambos modelos es superior a 1 lo cual es indicativo que habría que incluir el suavizado bivariante en el modelo.

A continuación se mirarán los residuos para ver cómo es su comportamiento.

```{r}
par(mfrow=c(2,2))
gam.check(gam1a)
gam.check(gam1b)
```

Se observa que los k index dan un valor de 1 o superior y con un p valor no significativo, lo cual es indicativo de que el número de nodos seleccionados es el correcto,

Con respecto a los residuos parece que el modelo ajustado por thin plate genera un gráfico QQ con unas colas bastante separadas y largas y además los residuos se distribuyen tomando una ligera forma de trompeta. Por el contrario, los residuos del modelo ajustado por tensor product parece que cumplen las condiciones de normalidad (gráfico QQ e histograma) y hemocedasticidad (gráfico de dispersión).

```{r}
plot(gam1a$fitted.values,gam1b$fitted.values, xlab='Thin plate',ylab='Tensor product')
abline(0,1)
```

Se aprecia en la gráfica de valores ajustados de ambos modelos que los valores se parecen mucho y se ajustan a la recta 0,1. Parece que una buena parte de los valores tienden a quedarse por debajo de la recta, sin embargo, en caso de aumentar el número de nodos en el modelo que usa tensor product los valores tienden a acercarse más a la recta.
Cabe mencionar la presencia de un valor muy alejado del resto que posiblemente sea el causante de posibles problemas en el paso de las condiciones de aplicabilidad.

```{r}
#Bondad de ajuste
#Thin Plate
shapiro.test(residuals(gam1a, type='deviance'))

grupos <- cut(gam1a$fitted.values, quantile(gam1a$fitted.values, (0:4)/4))
lawstat::levene.test(residuals(gam1a, type='deviance'), grupos)

#Tensor Product
shapiro.test(residuals(gam1b, type='deviance'))

grupos <- cut(gam1b$fitted.values, quantile(gam1b$fitted.values, (0:4)/4))
lawstat::levene.test(residuals(gam1b, type='deviance'), grupos)
```

Se aprecia que el modelo resultado del ajuste con la base thin plate no pasa la condición de normalidad (0.0002) pero si la de homocedasticidad (0.12).
Por el contrario, el modelo obtenido por tensor product pasa ambos test con valores de 0.23 para el normal y para el test de levene de 0.205. 
Por lo tanto en este caso el modelo con un ajuste bivariante con la base tensor product será el idóneo para explicar los casos notificados, por lo que el modelo quedaría así:

$log(\lambda)=\beta_0+f(t_i,c_i)$
$\lambda=exp(\beta_0+f(t_i,c_i))$


La media del número de casos es el resultado de la exponencial de un valor fijo mas el suavizado de la población total y el porcentaje de población menor de 5 años.

# Apartado 3

En este apartado se planteará un modelo GAM igual que el anterior pero incluyendo las variables de geolocalización de forma bivariante para poder ver si esto produce una mejora con respecto al modelo anterior.

```{r}
gam2<- gam(Counts13~te(Total_Pob13,por_menor5)+te(x,y),family = poisson)
summary(gam2)
```

Se puede observar que el edf de ambas suavizaciones se aleja bastante de 1 lo cual indica que es necesaria la introducción de ese alisado bivariante tanto en las variables de geolocalización como en las otras. Esto implica que a ambas variables se les va a aplicar la misma función de suavizado en el ajuste no paramétrico.

Aparte, los valores de deviance explicada, $R^2$ ajustado y AIC son de 88.1%, 0.79 y 414.71 respectivamente en contraposición a los valores del modelo anterior: 87.1% (explica menos deviance), 0.79 (igual $R^2$ ajustado) y un AIC de 447.21 (ligeramente mayor). 
Hay diferencias entre ambos modelos que indican el decantarse por el modelo que incluye la geolocalización, pero antes de decidir se realizará un análisis $X^2$ de la diferencia de deviances para ver si estas diferencias son significativas.

```{r}
#Comparación mediante chi cuadrado
pchisq(abs(gam2$deviance-gam1b$deviance), abs(gam2$df.residual-gam1b$df.residual),lower.tail = FALSE)
```

El análisis $X^2$ dice que hay diferencias entre ambos modelos por lo que el modelo con el que nos quedamos sería el que incluye la variable de geolocalización a la que se le ha aplicado el suavizado bivariante.

A continuación se valorará la bonda de ajuste del modelo.

```{r}
par(mfrow=c(2,2))
gam.check(gam2)
```

Se aprecia que el k index es muy cercano a 1 (1.06 y 0.96) lo cual informa de que el número de nodos elegidos es idóneo, además el p valor sale como no sgnificativo por lo que se acepta la hipótesis nula de que el número de nodos es el adecuado.

Con respecto al gráfico de los residuos, se aprecia en tanto en el histograma como en el gráfico QQ que los residuos tienden a ser normales. Sin embargo, parece que en el gráfico de dispersión hay una pequeña congregación a la derecha.

Para poder valorar el ajuste mas finamente se aplicarán los test de Shapiro y Levene.
```{r}
#Bondad de ajuste
shapiro.test(residuals(gam2, type='deviance'))

grupos <- cut(gam2$fitted.values, quantile(gam2$fitted.values, (0:4)/4))
lawstat::levene.test(residuals(gam2, type='deviance'), grupos)
```

El modelo pasa las hipótesis de normalidad (p valor de .71) y heterocedasticidad no con un valor de 0.002. 
Mencionar que la hipótesis de heterocedasticidad en caso de haber aumentado el número de los grupos a 6 se habría cumplido (p valor de 0.06).
Probablemente eliminando el valor atípico visto anteriormente en la descriptiva o realizando un ajuste mediante una distribución binomial negativa este problema podría solventarse.

Por lo que, si se da por bueno, el modelo final tendrá esta forma:

$log(\lambda)=\beta_0+f(t_i,c_i)+f(x_i,y_i)$

$\lambda=exp(\beta_0+f(t_i,c_i)+f(x_i,y_i))$

En donde el logaritmo de la media de casos es el resultado de la exponencial de un valor fijo mas el suavizado del lugar en el que se encuentra la persona con varicela y el suavizado de el total de la población en la que se encuentra junto con el porcentaje de niños menores de 5 años de esa población.























